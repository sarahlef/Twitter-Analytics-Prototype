{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9eef0f91-a19a-4409-9aa8-d9ceb7d3ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy #api package handler\n",
    "import csv #to store results in csv files \n",
    "import os \n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "from collections import Counter\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c48bc706-5213-4283-959a-eeaccc490717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#credentials\n",
    "api_key = 'BpiMXpXrKoyq6TRaVEvu4NUUr'\n",
    "api_key_secret = 'FdzzCKpQ4s75cGKXKQQCnSZNvu3nbsqlsX0vlSMJ7wPk9vLRxz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78870e9a-f64b-4805-b3af-086680def12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get access to tweeter api\n",
    "auth = tweepy.AppAuthHandler(api_key, api_key_secret) #send OAuth request\n",
    "api = tweepy.API(auth) #create API object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f47abc67-7f05-4ebc-9262-36bfcafb5b62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter keywords as folling: word1, word2, ....\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Doctor, Japan\n"
     ]
    }
   ],
   "source": [
    "#get keywords from user\n",
    "#input must be: word1, word2, .....\n",
    "print('Enter keywords as folling: word1, word2, ....')\n",
    "userInput = input() #ask user for inputs\n",
    "userInput = userInput.replace(', ', ',').replace(' ,', ',') #prepare input to convert it into array\n",
    "keywordsArray = userInput.split(',') #conver input to array\n",
    "#print(keywordsArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5318e6e7-e482-4eeb-a247-97bdb80d1a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#consume api and store result in array of 5 columns [key, created_at, text, username, trend]\n",
    "\n",
    "total_found = 0 #to count how many rows received from api\n",
    "start_time = time.time() #start chronometer\n",
    "\n",
    "tweetArray = [] #toring api result in array\n",
    "trendCollection = [] #collect all posts trends\n",
    "\n",
    "for key in keywordsArray:\n",
    "    for tweet in tweepy.Cursor(api.search, q=key).items(200): #nb of queries set to 200 to not overquery the api, to set queries to unlimited just put: .items()\n",
    "        \n",
    "        isEmpty = len(tweet.entities['hashtags']) #check if post has hashtag\n",
    "        trend = tweet.entities['hashtags'][0]['text'] if isEmpty!=0 else ''    #get first tag only\n",
    " \n",
    "        created_at = tweet.created_at\n",
    "        text = tweet.text\n",
    "        username = tweet.user.screen_name\n",
    "\n",
    "        tweetArray.append([key, created_at, text, username, trend]) #store tweet record\n",
    "        trendCollection.append(trend) #store tweet tag\n",
    "\n",
    "        total_found = total_found + 1 #track records got as an api resonse\n",
    "        \n",
    "end_time = time.time() #chrono ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cee60fb9-1728-4076-aaf6-ff0d027a0cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Prepare Tags array helpers, ######\n",
    "tags = list(set(trendCollection)) #delete duplication from trendCollection array\n",
    "tagWithOccurance = [] #array of tag with its occurence\n",
    "\n",
    "for tag in tags:\n",
    "    tagWithOccurance.append([tag, trendCollection.count(tag)])\n",
    "#print(tags)\n",
    "#print(tagWithOccurance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e3620e7-7b32-4751-96af-87b40c897287",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cfbcbc64-3667-4983-8809-70f3b801640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## GLOBAL API RESULT & CREATE CSV ##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1c3ad9d-8d0b-4151-b9b9-5ac89c7fef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Default tweets :: array of 6 columns with a tagOccurence [key, created_at, text, username, trend, tagOccurence]\n",
    "finalTweet = []\n",
    "for item in tweetArray:\n",
    "    tagName = item[4] #get row tagname\n",
    "    tagIndex = tags.index(tagName) #get index of the tagName on tag[]\n",
    "    tagOccurence = tagWithOccurance[tagIndex][1] #get occurence in tagOccurence0-\n",
    "    finalTweet.append([item[0], item[1], item[2], item[3], item[4], tagOccurence]) #store record "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97414dba-6941-4c04-8596-e4b073afadf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Default tweets csv\n",
    "with open('defaultResults.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    filednames = [\"keyword\", \"created_at\", \"text\", \"username\", \"tag\", \"tag occurence\"] #define csv header\n",
    "    writer = csv.DictWriter(file, fieldnames=filednames) \n",
    "    writer.writeheader() #write csv's header\n",
    "    writer = csv.writer(file, delimiter=',')\n",
    "    writer.writerows(finalTweet) #store all finalTweet's record (default records)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f331330-5a04-431c-b2e1-3d3b157a46e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Sorted tweets by tag occurence\n",
    "finalTweet.sort(key=lambda x: x[5], reverse=True) #sorted on descandant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a2ef2a8-9d1a-41ac-9495-53aec70f7de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Sorted tweets by tag occurence csv\n",
    "with open('classifiedByOccurence.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    filednames = [\"keyword\", \"created_at\", \"text\", \"username\", \"tag\", \"tag occurence\"] #define csv header\n",
    "    writer = csv.DictWriter(file, fieldnames=filednames)\n",
    "    writer.writeheader() #write csv's header\n",
    "    writer = csv.writer(file, delimiter=',')\n",
    "    writer.writerows(finalTweet) #store all finalTweet's record (default records)\n",
    "    file.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "916536fa-5ca4-42b3-aafa-3b8e243bbba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a6c9c15-e081-4e30-833e-d5713a4e0d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## TOP 10 TAGS ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a00bfa86-42c7-4a1f-bd0e-7f1921bdc989",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- FUNCTIONS --------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db7c4e62-5cd6-40cc-9123-21170a616c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Day Top tag, returns list of top hashtags of a day of the week\n",
    "def getTopDayTag(nbDays):\n",
    "    tagDayCollection_temp = [] #colloect tags of the day\n",
    "    \n",
    "    askedDay = datetime.date.today() - datetime.timedelta(days=nbDays) #find the day's date\n",
    "    dayStart = datetime.datetime(askedDay.year, askedDay.month, askedDay.day, 0) #set day start\n",
    "    dayEnd = datetime.datetime(askedDay.year, askedDay.month, askedDay.day, 23, 59, 59) #set day end\n",
    "    \n",
    "    for item in finalTweet:\n",
    "        if item[1] >= dayStart and item[1] <= dayEnd:\n",
    "            tagDayCollection_temp.append(item[4]) #store item's hashtag\n",
    "    \n",
    "    topDayTag = sorted(set(tagDayCollection_temp), key = lambda ele: tagDayCollection_temp.count(ele), reverse=True) #sort resulted hashtags by occurence descendant\n",
    "    if len(topDayTag) != 0: #if topDayTag was not empty\n",
    "        topDayTag.remove('')  #to remove the no tag case\n",
    "    \n",
    "    return topDayTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e5367d2-4264-48f4-b12e-8b7b5582b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hour Top Tag, returns list of top hashtags of a given hour of the day\n",
    "def getTopHourTag(nbHours):\n",
    "    tagHourCollection_temp = [] #colloect tags of this hour\n",
    "\n",
    "    askedHour = datetime.datetime.today() - datetime.timedelta(hours=nbHours) #find the current hour\n",
    "    hourStart = datetime.datetime(askedHour.year, askedHour.month, askedHour.day, askedHour.hour, 0) #set hour start\n",
    "    hourEnd = datetime.datetime(askedHour.year, askedHour.month, askedHour.day, askedHour.hour, 59) #set hour end\n",
    "\n",
    "    for item in finalTweet:\n",
    "        if item[1] >= hourStart and item[1] <= hourEnd: #if datStart < item's date < dayEnd\n",
    "            tagHourCollection_temp.append(item[4]) #store item's hashtag\n",
    "\n",
    "    #hour tags\n",
    "    topHourTag = sorted(set(tagHourCollection_temp), key = lambda ele: tagHourCollection_temp.count(ele), reverse=True) #sort resulted hashtags by occurence descendant\n",
    "    if len(topHourTag) != 0: #if topDayTag was not empty\n",
    "        topHourTag.remove('') #to remove the no tag case\n",
    "\n",
    "    return topHourTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e119fb3a-00c9-4456-ad27-be43e7eb4647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- DISPLAY RESULT --------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f63cf975-cc53-420d-bbf7-9041bb729886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array to string\n",
    "def listToString(L):  \n",
    "    return \", \".join(str(x) for x in L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c8929578-7d06-4693-915a-45eaf75edbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mTotal time spent to get results\u001b[0m: 25.8001 seconds\n",
      "\u001b[4mTotal rows found from api\u001b[0m: 400 rows\n"
     ]
    }
   ],
   "source": [
    "#General Details\n",
    "time_lapsed = format(end_time - start_time, \".4f\")\n",
    "print('\\033[4m' + 'Total time spent to get results' + '\\033[0m' + ':', end =\" \")\n",
    "print(time_lapsed + ' seconds') #chorometer counts\n",
    "print('\\033[4m' + 'Total rows found from api' + '\\033[0m' + ':', end =\" \")\n",
    "print(total_found, end=\" \") #total rows caught from api\n",
    "print('rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "49d7798a-be55-4475-8261-4e22a4d1bc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Hashtags of the week : \n",
      "'SWITCH_ON', 'tbs', 'TWICE', 'MiVidaMiOxigeno', '三浦春馬', 'BARFOUT', 'Metroid', 'Purgatell', 'YUTA', 'Hybrid'\n"
     ]
    }
   ],
   "source": [
    "#Top10 tag week tag\n",
    "print('Top 10 Hashtags of the week : ')\n",
    "topWeekTag = sorted(set(trendCollection), key = lambda ele: trendCollection.count(ele), reverse=True) #sort hashtags by occurence, descendant\n",
    "topWeekTag.remove('')  #to remove the no hashtag case\n",
    "print(str(topWeekTag[:10]).strip('[]')) #print as string list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "81bfd6c8-d359-4c2c-a89d-5aad6b60e843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Hashtags for each day of the week : \n",
      "2021-07-21 : \n",
      "2021-07-20 : SWITCH_ON, tbs, TWICE, MiVidaMiOxigeno, 三浦春馬, BARFOUT, Metroid, Purgatell, YUTA, Hybrid\n",
      "2021-07-19 : \n",
      "2021-07-18 : \n",
      "2021-07-17 : \n",
      "2021-07-16 : \n",
      "2021-07-15 : \n"
     ]
    }
   ],
   "source": [
    "#Top10 tag days of the week tag\n",
    "print('Top 10 Hashtags for each day of the week : ')\n",
    "for i in range(7):\n",
    "    askedDay = datetime.date.today() - datetime.timedelta(days=i) #set a day of the 7 days (1 week)\n",
    "    print(askedDay, end=\" \")\n",
    "    print(':', end=\" \")\n",
    "    result = listToString(getTopDayTag(i)[:10]) #get top 10 hashtags of setted day\n",
    "    print(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "304a6c53-e7a0-4370-bf8b-c9949ada9821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Hashtags for each hour of today\n",
      "2021-07-21\n",
      "0 \t: \n",
      "23 \t: SWITCH_ON, tbs, TWICE, MiVidaMiOxigeno, 三浦春馬, BARFOUT, Metroid, Purgatell, YUTA, Hybrid\n",
      "22 \t: \n",
      "21 \t: \n",
      "20 \t: \n",
      "19 \t: \n",
      "18 \t: \n",
      "17 \t: \n",
      "16 \t: \n",
      "15 \t: \n",
      "14 \t: \n",
      "13 \t: \n",
      "12 \t: \n",
      "11 \t: \n",
      "10 \t: \n",
      "9 \t: \n",
      "8 \t: \n",
      "7 \t: \n",
      "6 \t: \n",
      "5 \t: \n",
      "4 \t: \n",
      "3 \t: \n",
      "2 \t: \n",
      "1 \t: \n"
     ]
    }
   ],
   "source": [
    "#Top10 tags per hours of tag\n",
    "print('Top 10 Hashtags for each hour of today')\n",
    "print(datetime.date.today())\n",
    "for i in range(24):\n",
    "    askedHour = datetime.datetime.today() - datetime.timedelta(hours=i) #set an hour of the current day\n",
    "    print(askedHour.hour, end=\" \")\n",
    "    print('\\t:', end=\" \")\n",
    "    result = listToString(getTopHourTag(i)[:10]) #get top 10 hashtags of setted hour\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02969573-e39b-43fb-bbef-6c6d155bc96e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
